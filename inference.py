from utils import webSearch, llmCompression


PROMPT = """<start_of_turn>user
You are an expert product recommendation AI assistant trained to:
1. Compare products objectively based on features and specifications.
2. Provide personalized recommendations considering user needs.
3. Explain the pros and cons of each product clearly.
4. Support recommendations with factual information.

[System]
ë‹¹ì‹ ì€ ì œí’ˆ ì¶”ì²œê³¼ ë¹„êµë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.
ë§ˆì§€ë§‰ì—ëŠ” í•­ìƒ 'ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ë¹„êµë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ™‚'ë¼ëŠ” ë§ì„ ë¶™ì—¬ì£¼ì„¸ìš”.

[Instruction]
ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ë”ë¼ë„, ê·¸ ì‚¬ì‹¤ì„ ì–¸ê¸‰í•˜ì§€ ë§ê³  í˜„ì¬ ë³´ìœ í•œ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

[Question]
{query}

[Context]
ì„¤ëª…: {context}
<end_of_turn>
<start_of_turn>model
""".strip()


def inference(pipe, query):
    """
    pipe: í—ˆê¹…í˜ì´ìŠ¤ì˜ íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
    query: ì‚¬ìš©ìì˜ ì§ˆë¬¸
    """

    # í…ìŠ¤íŠ¸ ì •ë¦¬ í•¨ìˆ˜(ì…ë ¥ í…ìŠ¤íŠ¸ ì •ë¦¬)
    def clean_text(text):
        return text.strip().replace('\n', ' ').replace('  ', ' ')  #strip(): ì•ë’¤ ê³µë°± ì œê±°
                                                                   #replace('\n', ' '): ì¤„ë°”ê¿ˆ -> ê³µë°± ë³€í™˜
                                                                   #replace('  ', ' '): ë‘ ê°œ ì´ìƒ ì—°ì† ê³µë°± í•˜ë‚˜ë¡œ ì¤„ì„
    
    # ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° RAG
    query = clean_text(query)
    raw_context = webSearch(query)
    preprocessed_context = llmCompression(pipe, raw_context)
    context = clean_text(preprocessed_context)

    # í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = PROMPT.format(query=query, context=context)

    # ëª¨ë¸ ì¶”ë¡ 
    generated_text = pipe(
        prompt,
        max_new_tokens=2048,
        truncation=True,
        return_full_text=False  # Exclude input prompt
    )[0]["generated_text"]

    # ëª¨ë¸ì˜ ë‹µë³€ ë¶€ë¶„ë§Œì„ ì¶”ì¶œí•œ ë¶€ë¶„
    response = generated_text.split("<end_of_turn>")[0].strip()
    return response